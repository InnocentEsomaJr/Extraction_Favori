{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de données DHIS2 basée sur un Favori\n",
    "\n",
    "Ce notebook permet d'extraire les données analytics d'un DHIS2 en utilisant un **favori** (visualization sauvegardée).\n",
    "\n",
    "Un favori dans DHIS2 contient une configuration prédéfinie :\n",
    "- Indicateurs ou éléments de données\n",
    "- Périodes\n",
    "- Unités d'organisation\n",
    "- Filtres et dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openhexa.sdk import workspace\n",
    "from openhexa.toolbox.dhis2 import DHIS2\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge les variables du fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "url = os.getenv(\"DHIS2_URL\")\n",
    "username = os.getenv(\"DHIS2_USER\")\n",
    "password = os.getenv(\"DHIS2_PASS\")\n",
    "\n",
    "# Connexion sécurisée\n",
    "dhis = DHIS2(url=url, username=username, password=password)\n",
    "\n",
    "print(f\"✅ Connecté à : {url} en tant que {username}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paramètres\n",
    "\n",
    "Entrez l'ID du favori à extraire. Vous pouvez trouver cet ID :\n",
    "- Dans l'URL du favori : `.../#/visualization/FAVORITE_ID`\n",
    "- Via la recherche dans la cellule suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID du favori à extraire\n",
    "# mldsgxAvIIi correspond à SHE Kongo Central\n",
    "FAVORITE_ID = \"ROzCY14OLTE\"  # Remplacez par l'ID de votre favori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Rechercher un favori par nom (optionnel)\n",
    "\n",
    "Si vous ne connaissez pas l'ID, vous pouvez rechercher par nom :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Récupérer les métadonnées du favori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_favorite_metadata(dhis2, favorite_id):\n",
    "    \"\"\"Récupère les métadonnées complètes d'un favori.\"\"\"\n",
    "    try:\n",
    "        favorite = dhis2.api.get(\n",
    "            f\"visualizations/{favorite_id}\",\n",
    "            params={\n",
    "                \"fields\": \"*,dataDimensionItems[*,indicator[id,displayName],dataElement[id,displayName]],\"\n",
    "                          \"organisationUnits[id,displayName],periods[*],columns[*],rows[*],filters[*]\"\n",
    "            }\n",
    "        )\n",
    "        return favorite\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la récupération du favori: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les métadonnées\n",
    "favorite_metadata = get_favorite_metadata(dhis, FAVORITE_ID)\n",
    "\n",
    "if favorite_metadata:\n",
    "    print(f\"Favori: {favorite_metadata.get('displayName', 'N/A')}\")\n",
    "    print(f\"Type: {favorite_metadata.get('type', 'N/A')}\")\n",
    "    print(f\"Dernière mise à jour: {favorite_metadata.get('lastUpdated', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extraire les données analytics du favori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_favorite_data(dhis2, favorite_id):\n",
    "    \"\"\"\n",
    "    Extrait les données analytics d'un favori DHIS2.\n",
    "    \n",
    "    Retourne un DataFrame avec les données et les métadonnées.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Méthode 1: Utiliser l'endpoint data du favori\n",
    "        response = dhis2.api.get(\n",
    "            f\"visualizations/{favorite_id}/data.json\"\n",
    "        )\n",
    "        \n",
    "        # Extraire les headers et les rows\n",
    "        headers = response.get(\"headers\", [])\n",
    "        rows = response.get(\"rows\", [])\n",
    "        \n",
    "        if not rows:\n",
    "            print(\"Aucune donnée trouvée pour ce favori.\")\n",
    "            return pd.DataFrame(), response\n",
    "        \n",
    "        # Créer le DataFrame\n",
    "        columns = [h.get(\"name\", h.get(\"column\", f\"col_{i}\")) for i, h in enumerate(headers)]\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "        \n",
    "        # Extraire les métadonnées pour le mapping des IDs vers les noms\n",
    "        metadata = response.get(\"metaData\", {})\n",
    "        \n",
    "        return df, metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction des données: {e}\")\n",
    "        return pd.DataFrame(), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les données\n",
    "df_raw, metadata = extract_favorite_data(dhis, FAVORITE_ID)\n",
    "\n",
    "print(f\"Nombre de lignes: {len(df_raw)}\")\n",
    "print(f\"Colonnes: {list(df_raw.columns)}\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enrichir les données avec les noms lisibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_dataframe_with_names(df, metadata):\n",
    "    \"\"\"\n",
    "    Enrichit le DataFrame en remplaçant les IDs par les noms lisibles.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    df_enriched = df.copy()\n",
    "    \n",
    "    # Récupérer le mapping des items\n",
    "    items = metadata.get(\"items\", {})\n",
    "    \n",
    "    # Colonnes typiques à enrichir\n",
    "    dimension_columns = [\"dx\", \"pe\", \"ou\", \"co\"]  # data, period, orgunit, category option\n",
    "    \n",
    "    for col in df_enriched.columns:\n",
    "        if col in dimension_columns or col.lower() in [\"dataelement\", \"indicator\", \"orgunit\", \"period\"]:\n",
    "            # Créer une colonne avec les noms\n",
    "            name_col = f\"{col}_name\"\n",
    "            df_enriched[name_col] = df_enriched[col].apply(\n",
    "                lambda x: items.get(x, {}).get(\"name\", x) if isinstance(items.get(x), dict) else x\n",
    "            )\n",
    "    \n",
    "    # Convertir la colonne value en numérique si présente\n",
    "    if \"value\" in df_enriched.columns:\n",
    "        df_enriched[\"value\"] = pd.to_numeric(df_enriched[\"value\"], errors=\"coerce\")\n",
    "    \n",
    "    return df_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrichir les données\n",
    "df_enriched = enrich_dataframe_with_names(df_raw, metadata)\n",
    "\n",
    "print(f\"Colonnes enrichies: {list(df_enriched.columns)}\")\n",
    "df_enriched.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copier et supprimer les colonnes inutiles\n",
    "# Utiliser df_enriched si disponible sinon df_final\n",
    "if 'df_enriched' in globals():\n",
    "\ttarget_df = df_enriched\n",
    "elif 'df_final' in globals():\n",
    "\ttarget_df = df_final\n",
    "else:\n",
    "\traise NameError(\"\")\n",
    "\n",
    "default_cols = ['Organisation unit ID', 'Organisation unit code', 'Organisation unit description',\n",
    "\t\t\t\t'Reporting month', 'Organisation unit parameter', 'Organisation unit is parent']\n",
    "\n",
    "# Si une variable columns_to_drop est définie, l'ajouter\n",
    "if 'columns_to_drop' in globals() and isinstance(columns_to_drop, list) and columns_to_drop:\n",
    "\tcols_to_drop = list(dict.fromkeys(default_cols + columns_to_drop))\n",
    "else:\n",
    "\tcols_to_drop = default_cols\n",
    "\n",
    "# Ne supprimer que les colonnes existantes\n",
    "cols_existing = [c for c in cols_to_drop if c in target_df.columns]\n",
    "if cols_existing:\n",
    "\ttarget_df.drop(columns=cols_existing, inplace=True)\n",
    "else:\n",
    "\tprint(\"Aucune colonne à supprimer trouvée dans le DataFrame cible.\")\n",
    "\n",
    "target_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rapport Actuels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtre strict : contient 'actual reports' MAIS PAS 'time'\n",
    "col_actual_strict = [\n",
    "    c for c in target_df.columns \n",
    "    if 'actual reports' in c.lower() and 'time' not in c.lower()\n",
    "]\n",
    "\n",
    "if col_actual_strict:\n",
    "    # 2. Création du DataFrame de travail\n",
    "    df_actual = target_df[['Organisation unit'] + col_actual_strict].copy()\n",
    "    \n",
    "    # 3. Nettoyage numérique (force les nombres, remplace les vides par 0)\n",
    "    for col in col_actual_strict:\n",
    "        df_actual[col] = pd.to_numeric(df_actual[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # 4. Calcul de la somme par ligne\n",
    "    df_actual['Reports_Actual'] = df_actual[col_actual_strict].sum(axis=1)\n",
    "    \n",
    "    # 5. Arrondi à 1 chiffre après la virgule pour tout le tableau\n",
    "    df_actual = df_actual.round(1)\n",
    "    \n",
    "    # 6. Affichage du résultat\n",
    "    print(f\"Analyse basée sur {len(col_actual_strict)} indicateurs de type 'Actual Reports'\")\n",
    "    display(df_actual.head(15))\n",
    "else:\n",
    "    print(\"⚠️ Aucune colonne correspondant aux critères n'a été trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rapport Attendus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtre strict : contient 'expected reports' MAIS PAS 'time'\n",
    "col_actual_strict = [\n",
    "    c for c in target_df.columns \n",
    "    if 'expected reports' in c.lower() and 'time' not in c.lower()\n",
    "]\n",
    "\n",
    "if col_actual_strict:\n",
    "    # 2. Création du DataFrame de travail\n",
    "    df_actual = target_df[['Organisation unit'] + col_actual_strict].copy()\n",
    "    \n",
    "    # 3. Nettoyage numérique (force les nombres, remplace les vides par 0)\n",
    "    for col in col_actual_strict:\n",
    "        df_actual[col] = pd.to_numeric(df_actual[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # 4. Calcul de la somme par ligne\n",
    "    df_actual['Reports_Attendu'] = df_actual[col_actual_strict].sum(axis=1)\n",
    "    \n",
    "    # 5. Arrondi à 1 chiffre après la virgule pour tout le tableau\n",
    "    df_actual = df_actual.round(1)\n",
    "    \n",
    "    # 6. Affichage du résultat\n",
    "    print(f\"Analyse basée sur {len(col_actual_strict)} indicateurs de type 'Expected Reports'\")\n",
    "    display(df_actual.head(15))\n",
    "else:\n",
    "    print(\"⚠️ Aucune colonne correspondant aux critères n'a été trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Taux de déclaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Extraction ciblée : On veut 'reporting rate' MAIS PAS 'on time'\n",
    "col_rate_uniquement = [\n",
    "    c for c in target_df.columns \n",
    "    if 'reporting rate' in c.lower() and 'on time' not in c.lower()\n",
    "]\n",
    "\n",
    "if col_rate_uniquement:\n",
    "    # 2. Création du DataFrame avec l'unité d'organisation\n",
    "    df_affichage = target_df[['Organisation unit'] + col_rate_uniquement].copy()\n",
    "    \n",
    "    # 3. Nettoyage et arrondi à 1 chiffre après la virgule\n",
    "    for col in col_rate_uniquement:\n",
    "        # Conversion en numérique (force les erreurs en NaN puis remplace par 0)\n",
    "        df_affichage[col] = pd.to_numeric(df_affichage[col], errors='coerce').fillna(0)\n",
    "        # Application de la règle d'arrondi\n",
    "        df_affichage[col] = df_affichage[col].round(1)\n",
    "    \n",
    "    # 4. Affichage simple (sans calcul de somme)\n",
    "    print(f\"Affichage de {len(col_rate_uniquement)} indicateurs de complétude :\")\n",
    "    display(df_affichage.head(15))\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Aucune colonne de 'reporting rate' (hors 'on time') n'a été trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Complétude Globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Détection automatique et filtrage strict (Exclut 'on time')\n",
    "# On cherche les colonnes 'actual' et 'expected' mais on élimine celles qui contiennent 'time'\n",
    "actual_cols = [c for c in target_df.columns \n",
    "               if 'actual reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "expected_cols = [c for c in target_df.columns \n",
    "                 if 'expected reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "# 2. Création du DataFrame de synthèse\n",
    "df_synthese = target_df[['Organisation unit']].copy()\n",
    "\n",
    "# 3. Calculs des sommes avec conversion numérique forcée\n",
    "# On applique l'arrondi à 1 chiffre après la virgule sur les sommes\n",
    "df_synthese['Reports_Actual'] = target_df[actual_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "df_synthese['Reports_Attendu'] = target_df[expected_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# 4. Calcul de la Complétude avec sécurité contre la division par zéro\n",
    "df_synthese['Complétude_Globale (%)'] = (\n",
    "    df_synthese['Reports_Actual'] / df_synthese['Reports_Attendu'].replace(0, np.nan)\n",
    ") * 100\n",
    "\n",
    "# 5. Application de l'arrondi final à 1 chiffre après la virgule\n",
    "df_synthese['Complétude_Globale (%)'] = df_synthese['Complétude_Globale (%)'].fillna(0).round(1)\n",
    "\n",
    "# 6. Affichage final propre\n",
    "cols_finales = ['Organisation unit', 'Reports_Actual', 'Reports_Attendu', 'Complétude_Globale (%)']\n",
    "display(df_synthese[cols_finales].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Taux de déclaration & Complétude globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IDENTIFICATION AUTOMATIQUE DES COLONNES (Filtre strict sans \"on time\")\n",
    "col_rate_uniquement = [c for c in target_df.columns \n",
    "                       if 'reporting rate' in c.lower() and 'on time' not in c.lower()]\n",
    "\n",
    "actual_cols = [c for c in target_df.columns \n",
    "               if 'actual reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "expected_cols = [c for c in target_df.columns \n",
    "                 if 'expected reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "# 2. CRÉATION DU DATAFRAME DE SYNTHÈSE\n",
    "# On commence par l'unité d'organisation\n",
    "df_final = target_df[['Organisation unit']].copy()\n",
    "\n",
    "# 3. TRAITEMENT DES REPORTING RATES INDIVIDUELS\n",
    "for col in col_rate_uniquement:\n",
    "    # Conversion numérique + Arrondi à 1 rang\n",
    "    df_final[col] = pd.to_numeric(target_df[col], errors='coerce').fillna(0).round(1)\n",
    "\n",
    "# 4. CALCULS POUR LA COMPLÉTUDE GLOBALE\n",
    "# Somme des rapports réels (Actual)\n",
    "df_final['Reports_Actual'] = target_df[actual_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# Somme des rapports attendus (Attendu)\n",
    "df_final['Reports_Attendu'] = target_df[expected_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# Calcul du pourcentage global\n",
    "df_final['Complétude_Globale (%)'] = (\n",
    "    df_final['Reports_Actual'] / df_final['Reports_Attendu'].replace(0, np.nan)\n",
    ") * 100\n",
    "\n",
    "# Arrondi final du pourcentage global\n",
    "df_final['Complétude_Globale (%)'] = df_final['Complétude_Globale (%)'].fillna(0).round(1)\n",
    "\n",
    "# 5. ORGANISATION ET AFFICHAGE DES COLONNES\n",
    "# On affiche : Unité d'organisation + les taux par programme + la complétude globale\n",
    "cols_a_afficher = ['Organisation unit'] + col_rate_uniquement + ['Reports_Actual', 'Reports_Attendu', 'Complétude_Globale (%)']\n",
    "\n",
    "display(df_final[cols_a_afficher].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Mise en forme conditionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. IDENTIFICATION ET CALCULS ---\n",
    "col_rate_uniquement = [c for c in target_df.columns if 'reporting rate' in c.lower() and 'on time' not in c.lower()]\n",
    "actual_cols = [c for c in target_df.columns if 'actual reports' in c.lower() and 'time' not in c.lower()]\n",
    "expected_cols = [c for c in target_df.columns if 'expected reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "df_final = target_df[['Organisation unit']].copy()\n",
    "\n",
    "# Traitement des taux individuels\n",
    "for col in col_rate_uniquement:\n",
    "    df_final[col] = pd.to_numeric(target_df[col], errors='coerce').fillna(0).round(1)\n",
    "\n",
    "# Somme des rapports (Arrondi à 1 décimale)\n",
    "df_final['Reports_Actual'] = target_df[actual_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "df_final['Reports_Attendu'] = target_df[expected_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# Score NB.SI (Programmes >= 95%)\n",
    "df_final['Nombre des data set complétude >/=95%'] = (df_final[col_rate_uniquement] >= 95).sum(axis=1)\n",
    "\n",
    "# Complétude Globale\n",
    "df_final['Complétude_Globale (%)'] = (df_final['Reports_Actual'] / df_final['Reports_Attendu'].replace(0, np.nan)) * 100\n",
    "df_final['Complétude_Globale (%)'] = df_final['Complétude_Globale (%)'].fillna(0).round(1)\n",
    "\n",
    "# --- 2. FONCTIONS DE COLORATION ---\n",
    "\n",
    "def style_taux(val):\n",
    "    try: val = float(val)\n",
    "    except: return ''\n",
    "    if val < 50: return 'color: white; background-color: #FF0000'\n",
    "    elif 50 <= val <= 69: return 'color: white; background-color: #800000'\n",
    "    elif 70 <= val <= 79: return 'color: black; background-color: #FFFF00'\n",
    "    elif 80 <= val <= 95: return 'color: black; background-color: #32CD32'\n",
    "    elif 96 <= val <= 100: return 'color: white; background-color: #008000'\n",
    "    return ''\n",
    "\n",
    "def style_score(val):\n",
    "    try: val = int(val)\n",
    "    except: return ''\n",
    "    if val < 5: return 'color: white; background-color: #800000'\n",
    "    elif val == 5: return 'color: black; background-color: #FFC0CB'\n",
    "    elif 6 <= val <= 9: return 'color: black; background-color: #32CD32'\n",
    "    elif val == 10: return 'color: white; background-color: #008000'\n",
    "    elif val > 10: return 'color: white; background-color: #004d00'\n",
    "    return ''\n",
    "\n",
    "# --- 3. AFFICHAGE FINAL ---\n",
    "\n",
    "cols_finales = (['Organisation unit'] + col_rate_uniquement + \n",
    "                 ['Reports_Actual', 'Reports_Attendu', 'Complétude_Globale (%)', 'Nombre des data set complétude >/=95%'])\n",
    "\n",
    "# Colonnes à afficher avec une décimale\n",
    "cols_format_1d = col_rate_uniquement + ['Reports_Actual', 'Reports_Attendu', 'Complétude_Globale (%)']\n",
    "\n",
    "df_stylise = df_final[cols_finales].style.format({\n",
    "    col: \"{:.1f}\" for col in cols_format_1d\n",
    "}).applymap(style_taux, subset=col_rate_uniquement + ['Complétude_Globale (%)'])\\\n",
    "  .applymap(style_score, subset=['Nombre des data set complétude >/=95%'])\n",
    "\n",
    "display(df_stylise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export des données de complétude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. On définit le chemin\n",
    "excel_path = \"Rapport_Performance_Synthese.xlsx\"\n",
    "\n",
    "# 2. On exporte directement l'objet stylisé (celui qui a les couleurs)\n",
    "# On utilise 'openpyxl' comme moteur alternatif\n",
    "df_stylise.to_excel(excel_path, engine='openpyxl', index=False)\n",
    "\n",
    "print(f\"✅ Données exportées dans : {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. On définit le chemin\n",
    "csv_path = \"Rapport_Performance_Synthese.csv\"\n",
    "\n",
    "# 2. On exporte les données brutes du DataFrame (sans les couleurs, car CSV ne les supporte pas)\n",
    "# On utilise la propriété .data pour accéder au DataFrame sous-jacent\n",
    "df_stylise.data.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Données exportées dans : {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Actual Reports on Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Détection automatique et filtrage strict\n",
    "# On veut uniquement les colonnes qui contiennent 'actual reports on time'\n",
    "actual_cols = [c for c in target_df.columns \n",
    "               if 'actual reports on time' in c.lower()]\n",
    "\n",
    "# On garde les rapports attendus (qui n'ont généralement pas de mention 'time')\n",
    "expected_cols = [c for c in target_df.columns \n",
    "                 if 'expected reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "# 2. Création du DataFrame de synthèse\n",
    "df_synthese = target_df[['Organisation unit']].copy()\n",
    "\n",
    "# 3. Calculs des sommes avec conversion numérique forcée\n",
    "# On calcule le total des rapports reçus à temps\n",
    "df_synthese['Reports_Actual_on_time'] = target_df[actual_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# On calcule le total des rapports attendus\n",
    "df_synthese['Reports_Attendu'] = target_df[expected_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# 4. Calcul de la Complétude (Promptitude) avec sécurité\n",
    "df_synthese['Complétude_Globale (%)'] = (\n",
    "    df_synthese['Reports_Actual_on_time'] / df_synthese['Reports_Attendu'].replace(0, np.nan)\n",
    ") * 100\n",
    "\n",
    "# 5. Application de l'arrondi final\n",
    "df_synthese['Complétude_Globale (%)'] = df_synthese['Complétude_Globale (%)'].fillna(0).round(1)\n",
    "\n",
    "# 6. Affichage final\n",
    "cols_finales = ['Organisation unit', 'Reports_Actual_on_time', 'Reports_Attendu', 'Complétude_Globale (%)']\n",
    "display(df_synthese[cols_finales].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Promptitude Actual Report on Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtre strict : contient 'actual reports' MAIS PAS 'time'\n",
    "col_actual_strict = [\n",
    "    c for c in target_df.columns \n",
    "    if 'actual reports on time' in c.lower()\n",
    "]\n",
    "\n",
    "if col_actual_strict:\n",
    "    # 2. Création du DataFrame de travail\n",
    "    df_actual = target_df[['Organisation unit'] + col_actual_strict].copy()\n",
    "    \n",
    "    # 3. Nettoyage numérique (force les nombres, remplace les vides par 0)\n",
    "    for col in col_actual_strict:\n",
    "        df_actual[col] = pd.to_numeric(df_actual[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    # 4. Calcul de la somme par ligne\n",
    "    df_actual['Reports_Actual_on_time'] = df_actual[col_actual_strict].sum(axis=1)\n",
    "    \n",
    "    # 5. Arrondi à 1 chiffre après la virgule pour tout le tableau\n",
    "    df_actual = df_actual.round(1)\n",
    "    \n",
    "    # 6. Affichage du résultat\n",
    "    print(f\"Analyse basée sur {len(col_actual_strict)} indicateurs de type 'Actual Reports on Time'\")\n",
    "    display(df_actual.head(15))\n",
    "else:\n",
    "    print(\"⚠️ Aucune colonne correspondant aux critères n'a été trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Mise en forme conditionnelle de promptitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. IDENTIFICATION ET CALCULS (ON TIME UNIQUEMENT) ---\n",
    "\n",
    "# Filtrage pour ne garder que le \"On Time\"\n",
    "col_rate_uniquement = [c for c in target_df.columns if 'reporting rate' in c.lower() and 'on time' in c.lower()]\n",
    "actual_cols = [c for c in target_df.columns if 'actual reports' in c.lower() and 'on time' in c.lower()]\n",
    "expected_cols = [c for c in target_df.columns if 'expected reports' in c.lower() and 'time' not in c.lower()]\n",
    "\n",
    "df_final = target_df[['Organisation unit']].copy()\n",
    "\n",
    "# Traitement des taux individuels (Promptitude)\n",
    "for col in col_rate_uniquement:\n",
    "    df_final[col] = pd.to_numeric(target_df[col], errors='coerce').fillna(0).round(1)\n",
    "\n",
    "# Somme des rapports On Time et Attendus (Arrondi à 1 décimale)\n",
    "df_final['Reports_Actual_On_Time'] = target_df[actual_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "df_final['Reports_Attendu'] = target_df[expected_cols].apply(pd.to_numeric, errors='coerce').fillna(0).sum(axis=1).round(1)\n",
    "\n",
    "# Score NB.SI (Programmes On Time >= 95%)\n",
    "nom_col_score = 'Nombre des data set promptitude >/=95%'\n",
    "df_final[nom_col_score] = (df_final[col_rate_uniquement] >= 95).sum(axis=1)\n",
    "\n",
    "# Promptitude Globale\n",
    "df_final['Promptitude_Globale (%)'] = (df_final['Reports_Actual_On_Time'] / df_final['Reports_Attendu'].replace(0, np.nan)) * 100\n",
    "df_final['Promptitude_Globale (%)'] = df_final['Promptitude_Globale (%)'].fillna(0).round(1)\n",
    "\n",
    "# --- 2. FONCTIONS DE COLORATION ---\n",
    "\n",
    "def style_taux(val):\n",
    "    try: val = float(val)\n",
    "    except: return ''\n",
    "    if val < 50: return 'color: white; background-color: #FF0000' # Rouge\n",
    "    elif 50 <= val <= 69: return 'color: white; background-color: #800000' # Bordeaux\n",
    "    elif 70 <= val <= 79: return 'color: black; background-color: #FFFF00' # Jaune\n",
    "    elif 80 <= val <= 95: return 'color: black; background-color: #32CD32' # Vert citron\n",
    "    elif val > 95: return 'color: white; background-color: #008000' # Vert foncé\n",
    "    return ''\n",
    "\n",
    "def style_score(val):\n",
    "    try: val = int(val)\n",
    "    except: return ''\n",
    "    if val < 5: return 'color: white; background-color: #800000'\n",
    "    elif val == 5: return 'color: black; background-color: #FFC0CB'\n",
    "    elif 6 <= val <= 9: return 'color: black; background-color: #32CD32'\n",
    "    elif val == 10: return 'color: white; background-color: #008000'\n",
    "    elif val > 10: return 'color: white; background-color: #004d00'\n",
    "    return ''\n",
    "\n",
    "# --- 3. AFFICHAGE FINAL ---\n",
    "\n",
    "cols_finales = (['Organisation unit'] + col_rate_uniquement + \n",
    "                 ['Reports_Actual_On_Time', 'Reports_Attendu', 'Promptitude_Globale (%)', nom_col_score])\n",
    "\n",
    "# Colonnes à formater avec une décimale\n",
    "cols_format_1d = col_rate_uniquement + ['Reports_Actual_On_Time', 'Reports_Attendu', 'Promptitude_Globale (%)']\n",
    "\n",
    "df_stylise = df_final[cols_finales].style.format({\n",
    "    col: \"{:.1f}\" for col in cols_format_1d\n",
    "}).map(style_taux, subset=col_rate_uniquement + ['Promptitude_Globale (%)'])\\\n",
    "  .map(style_score, subset=[nom_col_score])\n",
    "\n",
    "display(df_stylise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Exportation des données de promptitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. On définit le chemin\n",
    "excel_path = \"Rapport_Promptitude_Synthese.xlsx\"\n",
    "\n",
    "# 2. On exporte directement l'objet stylisé (celui qui a les couleurs)\n",
    "# On utilise 'openpyxl' comme moteur alternatif\n",
    "df_stylise.to_excel(excel_path, engine='openpyxl', index=False)\n",
    "\n",
    "print(f\"✅ Données exportées dans : {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. On définit le chemin\n",
    "csv_path = \"Rapport_Promptitude_Synthese.csv\"\n",
    "\n",
    "# 2. On exporte les données brutes du DataFrame (sans les couleurs, car CSV ne les supporte pas)\n",
    "# On utilise la propriété .data pour accéder au DataFrame sous-jacent\n",
    "df_stylise.data.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Données exportées dans : {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
